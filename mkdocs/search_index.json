{
    "docs": [
        {
            "location": "/",
            "text": "JRuyi\n\uf0c1\n\n\nA Java framework for easily developing network applications as you wish.\n\n\nIntroduction\n\uf0c1\n\n\nJRuyi is a Java framework for easily developing \nefficient\n, \nscalable\n and \nflexible\n network applications.  It hides the Java socket API by providing an event-driven asynchronous API over various transports, such as TCP and UDP, via \nJava NIO\n.\n\n\n\n\nWhat is Ruyi?\n\n\nRuyi (Chinese: \u5982\u610f; pinyin: r\u00fay\u00ec; Wade\u2013Giles: ju-i; literally \"as [one] wishes; as [you] wish\") is a curved\ndecorative object that is a ceremonial sceptre in Chinese Buddhism or a talisman symbolizing power and good fortune\nin Chinese folklore.\n\nRead \nmore ...\n\n\n\n\nThe key features of JRuyi are listed as follows.\n\n\nModularity\n\uf0c1\n\n\nJRuyi is built on OSGi framework which is a dynamic module system and service platform.\n\n\nService Oriented\n\uf0c1\n\n\nJRuyi is an OSGi based framework; its functionality is mainly provided through services.\n\n\nAsynchronism\n\uf0c1\n\n\nJRuyi provides an event-driven asynchronous IO framework.\n\n\nPerformance\n\uf0c1\n\n\nHigh throughput, low latency; provides a thread-local cache mechanism to avoid frequent creation of large objects such as buffers; provides chained buffers to minimize unnecessary memory copy.\n\n\nTCP Connection Pooling and Multiplexing\n\uf0c1\n\n\nProvides an efficient IO service supporting TCP connection pooling and multiplexing.\n\n\nExtensible Command Line\n\uf0c1\n\n\nA command-line/shell backed by Apache Felix Gogo Runtime. New commands can be easily added via OSGi services.\n\n\nDynamic Configuration\n\uf0c1\n\n\nConfigurations can be created and updated dynamically through ruyi-cli.\n\n\nHot Deployment\n\uf0c1\n\n\nBundles can be installed, updated, started, stopped and uninstalled on the fly through ruyi-cli.\n\n\nDownload\n\uf0c1\n\n\nJRuyi is available in two distributions: \njruyi\n and \njruyi-core\n.\n\n\n\n\njruyi\n - An OSGi based runtime which provides a lightweight container.\n\n\njruyi-core\n - A single jar library(OSGi bundle) for being easily embedded/integrated into any runtime.\n\n\n\n\nGet jruyi\n\uf0c1\n\n\n\n\njruyi-2.4.1.zip\n [\nMD5\n] [\nSHA1\n]\n\n\njruyi-2.4.1.tar.gz\n [\nMD5\n] [\nSHA1\n]\n\n\n\n\nAll previous releases of JRuyi can be found \nhere\n.\n\n\nGet jruyi-core\n\uf0c1\n\n\nThe jar is available from JCenter: \njruyi-core-2.4.1.jar\n.\n\n\nTo get jruyi-core through Maven, please add the following to your POM.\n\n\n<repositories>\n    <repository>\n        <id>jcenter</id>\n        <url>https://jcenter.bintray.com/</url>\n    </repository>\n</repositories>\n\n<dependencies>\n    <dependency>\n        <groupId>org.jruyi</groupId>\n        <artifactId>jruyi-core</artifactId>\n        <version>2.4.1</version>\n    </dependency>\n</dependencies>\n\n\n\n\nTo get jruyi-core through Gradle, please add the following to your build script.\n\n\nrepositories {\n    jcenter()\n}\n\ndependencies {\n    compile \"org.jruyi:jruyi-core:2.4.1\"\n}\n\n\n\n\nSoftware Requirements\n\uf0c1\n\n\nOracle/OpenJDK JDK 7+ is required to run JRuyi.\n\n\nGetting a Feel for JRuyi\n\uf0c1\n\n\nPlease go to \nDownload\n to get the latest release of JRuyi. Unpack the archive that you downloaded, and then\nyou will get the directory \njruyi-2.4.1\n which will be referred as $JRUYI_HOME.\n\n\n\n\nNote:\n\n\nAll the instructions in this section are given under a UNIX-like environment. It should be very straightforward for\nyou to make them work on Windows. Just use the counterpart BAT command for a shell script mentioned later in this\nsection. For example, use ruyi.bat for ruyi and ruyi-cli.bat for ruyi-cli.\n\n\n\n\nPlease open a console, go to $JRUYI_HOME and run the following command to start JRuyi.\n\n\n$ bin/ruyi\n\n\n\n\nYou should see something printed similar as follows.\n\n\n21:28:37.190 INFO  [Ruyi] Start JRuyi (version=2.4.1)\n    ...\n21:28:37.191 INFO  [Ruyi] Instance Name: default\n    ...\n21:28:37.238 INFO  [BootLoader] Loading bundles...\n    ...\n21:28:37.437 INFO  [BootLoader] Done loading bundles\n21:28:37.658 INFO  [ExecutorService] Activating ExecutorService...\n21:28:37.663 INFO  [ExecutorService] ExecutorService activated: {corePoolSize=16, maxPoolSize=32, keepAliveTimeInSeconds=10, queueCapacity=8192, terminationWaitTimeInSeconds=60}\n21:28:37.684 INFO  [Scheduler] Scheduler activated: numberOfThreads=1\n21:28:37.706 INFO  [MessageQueue] MessageQueue activated\n21:28:37.788 INFO  [Provisioner] Start provisioning...\n    ...\n21:28:37.842 INFO  [Provisioner] Done provisioning\n21:28:37.871 INFO  [BufferFactory] BufferFactory: unitCapacity=8192\n21:28:37.873 INFO  [ChannelAdmin] Activating ChannelAdmin...\n21:28:37.885 INFO  [SelectorThread] jruyi-selector-0 started\n21:28:37.886 INFO  [ChannelAdmin] ChannelAdmin activated\n21:28:37.886 INFO  [SelectorThread] jruyi-selector-1 started\n21:28:37.889 INFO  [TcpAcceptor] Starting TcpAcceptor...\n21:28:37.889 INFO  [TcpAcceptor] TcpAcceptor started\n21:28:37.892 INFO  [TcpServer] Starting TcpServer[jruyi.clid]...\n21:28:37.896 INFO  [TcpServer] TcpServer[jruyi.clid] started, listening on /127.0.0.1:6060\n21:28:37.897 INFO  [ExecutorService] ExecutorService updated: {corePoolSize=16, maxPoolSize=32, keepAliveTimeInSeconds=10, queueCapacity=8192, terminationWaitTimeInSeconds=60}\n\n\n\n\nThe last line means that the JRuyi clid which is itself implemented using JRuyi IO framework, is up, and the JRuyi shell is ready to use.\n\n\nPlease open another console, go to $JRUYI_HOME and run the following command\n\n\n$ bin/ruyi-cli\n\n\n\n\nto enter the shell of JRuyi.\n\n\n    _ _ __           _\n   | | '_ \\_  _ _  _(_)\n __| |   _| || | || | |\n|___/|_|\\_\\____|\\__ |_|\n                |__/\n\nJRuyi (2.4.1)\nhttp://www.jruyi.org/\n\nEnter 'help' for a list of available commands.\nEnter 'help <command>' for more information on a specific command.\nEnter 'quit' or 'exit' to exit.\n\n\nlocalhost:6060>\n\n\n\n\nIn the mean time, you should see the following similar log is printed on the console in which JRuyi was started.\n\n\n21:31:35.452 DEBUG [TcpServer] TcpServer[jruyi.clid] Session#1: OPENED\n\n\n\n\nThis log means the ruyi-cli established a TCP connection to JRuyi clid for communication.\n\n\nNext, please enter \nhelp\n to get a list of available commands,\n\n\nlocalhost:6060> help\nbundle:inspect     bundle:install     bundle:list        bundle:refresh\nbundle:start       bundle:stop        bundle:uninstall   bundle:update\nconf:create        conf:delete        conf:exists        conf:list\nconf:update        io:list            io:start           io:stop\njruyi:echo         jruyi:gc           jruyi:grep         jruyi:help\njruyi:shutdown     jruyi:sysinfo      route:clear        route:delete\nroute:list         route:set          scr:config         scr:disable\nscr:enable         scr:info           scr:list           tpe:info\ntpe:profiling\nlocalhost:6060>\n\n\n\n\nEnter \nbundle:list\n to see a list of installed bundles.\n\n\nlocalhost:6060> bundle:list\nSTART LEVEL 12\n[ ID ][  State  ][Level][     Name     ]\n    0     Active    0    org.apache.felix.framework-5.4.0\n    1     Active    1    org.jruyi.osgi.log-2.0.2\n    2     Active    2    org.apache.felix.metatype-1.1.2\n    3     Active    2    org.apache.felix.configadmin-1.8.8\n    4     Active    3    org.apache.felix.scr-2.0.2\n    5     Active    6    org.jruyi.common-2.4.0\n    6     Active    6    org.jruyi.tpe-2.0.2\n    7     Active    6    org.jruyi.me-2.0.4\n    8     Active    6    org.jruyi.io-2.3.4\n    9     Active   10    org.apache.felix.gogo.runtime-0.16.2\n   10     Active   10    org.jruyi.cmd-2.0.4\n   11     Active   10    org.jruyi.clid-2.3.3\nlocalhost:6060>\n\n\n\n\nEnter \nconf:list\n to see configurations.\n\n\nlocalhost:6060> conf:list\n    jruyi.clid: {bindAddr=localhost, port=6060, sessionIdleTimeoutInSeconds=300}\n    jruyi.common.scheduler: {numberOfThreads=1, terminationWaitTimeInSeconds=60}\n    jruyi.tpe: {keepAliveTimeInSeconds=10, queueCapacity=8192, terminationWaitTimeInSeconds=60}\n    jruyi.me.mq: {msgTimeoutInSeconds=10}\n    jruyi.io.channeladmin: {numberOfSelectorThreads=0, numberOfIoThreads=0, capacityOfIoRingBuffer=4096}\nlocalhost:6060>\n\n\n\n\nNow, lets enter \nexit\n to exit the JRuyi shell.\n\n\nlocalhost:6060> exit\n\n\n\n\nAnd you should see the following similar log is printed on the console in which JRuyi was started.\n\n\n21:35:30.359 DEBUG [TcpServer] TcpServer[jruyi.clid] Session#1: CLOSED\n\n\n\n\nThis log says ruyi-cli is done the communication with JRuyi clid and closed the TCP connection.\n\n\nTo stop JRuyi, simply press ctrl-c in the console in which JRuyi was started.\nAlternatively, you can run the following command under $JRUYI_HOME.\n\n\n$ bin/ruyi-cli shutdown\n\n\n\n\nAnd you will get the following similar logs printed on the console in which JRuyi was started.\n\n\n21:37:25.038 INFO  [Ruyi] Stopping JRuyi...\n21:37:25.044 INFO  [TcpServer] Stopping TcpServer[jruyi.clid]...\n21:37:25.044 INFO  [TcpServer] TcpServer[jruyi.clid] stopped\n21:37:25.046 INFO  [TcpAcceptor] Stopping TcpAcceptor...\n21:37:25.046 INFO  [TcpAcceptor] TcpAcceptor stopped\n21:37:25.060 INFO  [ChannelAdmin] Deactivating ChannelAdmin...\n21:37:25.060 INFO  [SelectorThread] jruyi-selector-0 stopped\n21:37:25.061 INFO  [SelectorThread] jruyi-selector-1 stopped\n21:37:25.061 INFO  [ChannelAdmin] ChannelAdmin deactivated\n21:37:25.069 INFO  [MessageQueue] MessageQueue deactivated\n21:37:25.069 INFO  [ExecutorService] Deactivating ExecutorService...\n21:37:25.070 DEBUG [ExecutorService] TPE executor terminated\n21:37:25.070 INFO  [ExecutorService] ExecutorService deactivated\n21:37:25.074 INFO  [Scheduler] Scheduler deactivated\n21:37:25.082 INFO  [Ruyi] JRuyi stopped\n\n\n\n\nJavadoc\n\uf0c1\n\n\n\n\n\n\n\n\nName\n\n\nVersion\n\n\nOnline\n\n\nArchive\n\n\n\n\n\n\n\n\n\n\njruyi-api\n\n\n2.4.0\n\n\n[\nhtml\n]\n\n\n[\nzip\n] [\ntar.gz\n]\n\n\n\n\n\n\n\n\nLicense\n\uf0c1\n\n\nJRuyi is licensed under the \nApache License, Version 2.0\n.",
            "title": "Home"
        },
        {
            "location": "/#jruyi",
            "text": "A Java framework for easily developing network applications as you wish.",
            "title": "JRuyi"
        },
        {
            "location": "/#introduction",
            "text": "JRuyi is a Java framework for easily developing  efficient ,  scalable  and  flexible  network applications.  It hides the Java socket API by providing an event-driven asynchronous API over various transports, such as TCP and UDP, via  Java NIO .   What is Ruyi?  Ruyi (Chinese: \u5982\u610f; pinyin: r\u00fay\u00ec; Wade\u2013Giles: ju-i; literally \"as [one] wishes; as [you] wish\") is a curved\ndecorative object that is a ceremonial sceptre in Chinese Buddhism or a talisman symbolizing power and good fortune\nin Chinese folklore. \nRead  more ...   The key features of JRuyi are listed as follows.  Modularity \uf0c1  JRuyi is built on OSGi framework which is a dynamic module system and service platform.  Service Oriented \uf0c1  JRuyi is an OSGi based framework; its functionality is mainly provided through services.  Asynchronism \uf0c1  JRuyi provides an event-driven asynchronous IO framework.  Performance \uf0c1  High throughput, low latency; provides a thread-local cache mechanism to avoid frequent creation of large objects such as buffers; provides chained buffers to minimize unnecessary memory copy.  TCP Connection Pooling and Multiplexing \uf0c1  Provides an efficient IO service supporting TCP connection pooling and multiplexing.  Extensible Command Line \uf0c1  A command-line/shell backed by Apache Felix Gogo Runtime. New commands can be easily added via OSGi services.  Dynamic Configuration \uf0c1  Configurations can be created and updated dynamically through ruyi-cli.  Hot Deployment \uf0c1  Bundles can be installed, updated, started, stopped and uninstalled on the fly through ruyi-cli.",
            "title": "Introduction"
        },
        {
            "location": "/#download",
            "text": "JRuyi is available in two distributions:  jruyi  and  jruyi-core .   jruyi  - An OSGi based runtime which provides a lightweight container.  jruyi-core  - A single jar library(OSGi bundle) for being easily embedded/integrated into any runtime.   Get jruyi \uf0c1   jruyi-2.4.1.zip  [ MD5 ] [ SHA1 ]  jruyi-2.4.1.tar.gz  [ MD5 ] [ SHA1 ]   All previous releases of JRuyi can be found  here .  Get jruyi-core \uf0c1  The jar is available from JCenter:  jruyi-core-2.4.1.jar .  To get jruyi-core through Maven, please add the following to your POM.  <repositories>\n    <repository>\n        <id>jcenter</id>\n        <url>https://jcenter.bintray.com/</url>\n    </repository>\n</repositories>\n\n<dependencies>\n    <dependency>\n        <groupId>org.jruyi</groupId>\n        <artifactId>jruyi-core</artifactId>\n        <version>2.4.1</version>\n    </dependency>\n</dependencies>  To get jruyi-core through Gradle, please add the following to your build script.  repositories {\n    jcenter()\n}\n\ndependencies {\n    compile \"org.jruyi:jruyi-core:2.4.1\"\n}",
            "title": "Download"
        },
        {
            "location": "/#software-requirements",
            "text": "Oracle/OpenJDK JDK 7+ is required to run JRuyi.",
            "title": "Software Requirements"
        },
        {
            "location": "/#getting-a-feel-for-jruyi",
            "text": "Please go to  Download  to get the latest release of JRuyi. Unpack the archive that you downloaded, and then\nyou will get the directory  jruyi-2.4.1  which will be referred as $JRUYI_HOME.   Note:  All the instructions in this section are given under a UNIX-like environment. It should be very straightforward for\nyou to make them work on Windows. Just use the counterpart BAT command for a shell script mentioned later in this\nsection. For example, use ruyi.bat for ruyi and ruyi-cli.bat for ruyi-cli.   Please open a console, go to $JRUYI_HOME and run the following command to start JRuyi.  $ bin/ruyi  You should see something printed similar as follows.  21:28:37.190 INFO  [Ruyi] Start JRuyi (version=2.4.1)\n    ...\n21:28:37.191 INFO  [Ruyi] Instance Name: default\n    ...\n21:28:37.238 INFO  [BootLoader] Loading bundles...\n    ...\n21:28:37.437 INFO  [BootLoader] Done loading bundles\n21:28:37.658 INFO  [ExecutorService] Activating ExecutorService...\n21:28:37.663 INFO  [ExecutorService] ExecutorService activated: {corePoolSize=16, maxPoolSize=32, keepAliveTimeInSeconds=10, queueCapacity=8192, terminationWaitTimeInSeconds=60}\n21:28:37.684 INFO  [Scheduler] Scheduler activated: numberOfThreads=1\n21:28:37.706 INFO  [MessageQueue] MessageQueue activated\n21:28:37.788 INFO  [Provisioner] Start provisioning...\n    ...\n21:28:37.842 INFO  [Provisioner] Done provisioning\n21:28:37.871 INFO  [BufferFactory] BufferFactory: unitCapacity=8192\n21:28:37.873 INFO  [ChannelAdmin] Activating ChannelAdmin...\n21:28:37.885 INFO  [SelectorThread] jruyi-selector-0 started\n21:28:37.886 INFO  [ChannelAdmin] ChannelAdmin activated\n21:28:37.886 INFO  [SelectorThread] jruyi-selector-1 started\n21:28:37.889 INFO  [TcpAcceptor] Starting TcpAcceptor...\n21:28:37.889 INFO  [TcpAcceptor] TcpAcceptor started\n21:28:37.892 INFO  [TcpServer] Starting TcpServer[jruyi.clid]...\n21:28:37.896 INFO  [TcpServer] TcpServer[jruyi.clid] started, listening on /127.0.0.1:6060\n21:28:37.897 INFO  [ExecutorService] ExecutorService updated: {corePoolSize=16, maxPoolSize=32, keepAliveTimeInSeconds=10, queueCapacity=8192, terminationWaitTimeInSeconds=60}  The last line means that the JRuyi clid which is itself implemented using JRuyi IO framework, is up, and the JRuyi shell is ready to use.  Please open another console, go to $JRUYI_HOME and run the following command  $ bin/ruyi-cli  to enter the shell of JRuyi.      _ _ __           _\n   | | '_ \\_  _ _  _(_)\n __| |   _| || | || | |\n|___/|_|\\_\\____|\\__ |_|\n                |__/\n\nJRuyi (2.4.1)\nhttp://www.jruyi.org/\n\nEnter 'help' for a list of available commands.\nEnter 'help <command>' for more information on a specific command.\nEnter 'quit' or 'exit' to exit.\n\n\nlocalhost:6060>  In the mean time, you should see the following similar log is printed on the console in which JRuyi was started.  21:31:35.452 DEBUG [TcpServer] TcpServer[jruyi.clid] Session#1: OPENED  This log means the ruyi-cli established a TCP connection to JRuyi clid for communication.  Next, please enter  help  to get a list of available commands,  localhost:6060> help\nbundle:inspect     bundle:install     bundle:list        bundle:refresh\nbundle:start       bundle:stop        bundle:uninstall   bundle:update\nconf:create        conf:delete        conf:exists        conf:list\nconf:update        io:list            io:start           io:stop\njruyi:echo         jruyi:gc           jruyi:grep         jruyi:help\njruyi:shutdown     jruyi:sysinfo      route:clear        route:delete\nroute:list         route:set          scr:config         scr:disable\nscr:enable         scr:info           scr:list           tpe:info\ntpe:profiling\nlocalhost:6060>  Enter  bundle:list  to see a list of installed bundles.  localhost:6060> bundle:list\nSTART LEVEL 12\n[ ID ][  State  ][Level][     Name     ]\n    0     Active    0    org.apache.felix.framework-5.4.0\n    1     Active    1    org.jruyi.osgi.log-2.0.2\n    2     Active    2    org.apache.felix.metatype-1.1.2\n    3     Active    2    org.apache.felix.configadmin-1.8.8\n    4     Active    3    org.apache.felix.scr-2.0.2\n    5     Active    6    org.jruyi.common-2.4.0\n    6     Active    6    org.jruyi.tpe-2.0.2\n    7     Active    6    org.jruyi.me-2.0.4\n    8     Active    6    org.jruyi.io-2.3.4\n    9     Active   10    org.apache.felix.gogo.runtime-0.16.2\n   10     Active   10    org.jruyi.cmd-2.0.4\n   11     Active   10    org.jruyi.clid-2.3.3\nlocalhost:6060>  Enter  conf:list  to see configurations.  localhost:6060> conf:list\n    jruyi.clid: {bindAddr=localhost, port=6060, sessionIdleTimeoutInSeconds=300}\n    jruyi.common.scheduler: {numberOfThreads=1, terminationWaitTimeInSeconds=60}\n    jruyi.tpe: {keepAliveTimeInSeconds=10, queueCapacity=8192, terminationWaitTimeInSeconds=60}\n    jruyi.me.mq: {msgTimeoutInSeconds=10}\n    jruyi.io.channeladmin: {numberOfSelectorThreads=0, numberOfIoThreads=0, capacityOfIoRingBuffer=4096}\nlocalhost:6060>  Now, lets enter  exit  to exit the JRuyi shell.  localhost:6060> exit  And you should see the following similar log is printed on the console in which JRuyi was started.  21:35:30.359 DEBUG [TcpServer] TcpServer[jruyi.clid] Session#1: CLOSED  This log says ruyi-cli is done the communication with JRuyi clid and closed the TCP connection.  To stop JRuyi, simply press ctrl-c in the console in which JRuyi was started.\nAlternatively, you can run the following command under $JRUYI_HOME.  $ bin/ruyi-cli shutdown  And you will get the following similar logs printed on the console in which JRuyi was started.  21:37:25.038 INFO  [Ruyi] Stopping JRuyi...\n21:37:25.044 INFO  [TcpServer] Stopping TcpServer[jruyi.clid]...\n21:37:25.044 INFO  [TcpServer] TcpServer[jruyi.clid] stopped\n21:37:25.046 INFO  [TcpAcceptor] Stopping TcpAcceptor...\n21:37:25.046 INFO  [TcpAcceptor] TcpAcceptor stopped\n21:37:25.060 INFO  [ChannelAdmin] Deactivating ChannelAdmin...\n21:37:25.060 INFO  [SelectorThread] jruyi-selector-0 stopped\n21:37:25.061 INFO  [SelectorThread] jruyi-selector-1 stopped\n21:37:25.061 INFO  [ChannelAdmin] ChannelAdmin deactivated\n21:37:25.069 INFO  [MessageQueue] MessageQueue deactivated\n21:37:25.069 INFO  [ExecutorService] Deactivating ExecutorService...\n21:37:25.070 DEBUG [ExecutorService] TPE executor terminated\n21:37:25.070 INFO  [ExecutorService] ExecutorService deactivated\n21:37:25.074 INFO  [Scheduler] Scheduler deactivated\n21:37:25.082 INFO  [Ruyi] JRuyi stopped",
            "title": "Getting a Feel for JRuyi"
        },
        {
            "location": "/#javadoc",
            "text": "Name  Version  Online  Archive      jruyi-api  2.4.0  [ html ]  [ zip ] [ tar.gz ]",
            "title": "Javadoc"
        },
        {
            "location": "/#license",
            "text": "JRuyi is licensed under the  Apache License, Version 2.0 .",
            "title": "License"
        },
        {
            "location": "/getting-started/",
            "text": "Getting Started\n\uf0c1\n\n\nSome examples to let you get started quickly with JRuyi.\n\n\nTo get the source code of examples, please check \njruyi-examples\n on Github.\nIn the later sections, \n$JRUYI_EXAMPLES_HOME\n will be used to refer to the root directory of your local copy of the repo\n\njruyi-examples\n.  All the example projects are available in Gradle as well as Maven.\n\n\n\n\nNote:\n\n\nAll the examples are given under a UNIX-like environment. It should be very straightforward for you to make them\nwork on Windows. Just use the counterpart BAT file for a shell script file mentioned in the examples. For example,\nuse ruyi.bat for ruyi and ruyi-cli.bat for ruyi-cli.\n\n\n\n\nWe also assume that you know how to download JRuyi.  If you don't, please go check \nDownload\n. And we will\nuse \n$JRUYI_HOME\n to refer to the directory where the downloaded jruyi package is unpacked.\n\n\nBuilding a Discard Server\n\uf0c1\n\n\nLets start with writing a \ndiscard\n server which simply throws away any received data.\n\n\nTo implement a discard server, simply create an \nINioService\n\nof type TcpServer, and start it as the following code shows.\n\n\npackage org.jruyi.example.discard;\n\nimport org.jruyi.core.INioService;\nimport org.jruyi.core.ITcpServerConfiguration;\nimport org.jruyi.core.RuyiCore;\nimport org.jruyi.io.IBuffer;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\npublic class DiscardServer {\n\n    private static final Logger c_logger = LoggerFactory.getLogger(DiscardServer.class);\n\n    public static void main(String[] args) {\n        try {\n            // Build an Nio Service of type TcpServer\n            final INioService<IBuffer, Object, ? extends ITcpServerConfiguration> tcpServer = RuyiCore\n                    .newTcpServerBuilder()\n                    .port(10009)\n                    .serviceId(\"jruyi.example.discard\")\n                    .build();\n\n            // Start tcpServer\n            tcpServer.start();\n        } catch (Throwable t) {\n            c_logger.error(\"Failed to start discard server\", t);\n        }\n    }\n}\n\n\n\n\nSimple? Yeah, it is.  But there's a problem of this code that it cannot serve as a good demo.  Because there's no prove\nthat we actually got the data sent from a client.  So lets write a session listener and log the received data.\n\n\npackage org.jruyi.example.discard;\n\nimport org.jruyi.common.StrUtil;\nimport org.jruyi.io.IBuffer;\nimport org.jruyi.io.ISession;\nimport org.jruyi.io.SessionListener;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nclass DiscardServerListener extends SessionListener<IBuffer, Object> {\n\n    private static final Logger c_logger = LoggerFactory.getLogger(DiscardServerListener.class);\n\n    @Override\n    public void onMessageReceived(ISession session, IBuffer inMsg) {\n        c_logger.info(StrUtil.join(\"Got data >>\", StrUtil.getLineSeparator(), inMsg));\n    }\n}\n\n\n\n\nMethod \nDiscardServerListener.onMessageReceived\n will be invoked when any data arrives. And it dumps the received data.\n\n\nNext, lets hook this DiscardServerListener to the NioService before starting.\n\n\n...\n// Set sessionListener\ntcpServer.sessionListener(new DiscardServerListener());\n\n// Start tcpServer\ntcpServer.start();\n...\n\n\n\n\nNow, you should/can see what data the server gets.  However, this code is still not good enough.  You may have already\nnoticed that there's a \ntcpServer.start()\n but no call of stop, which means the NioService does not stop gracefully when this\napplication terminates.  What should we do then?  I'm not going to discuss the solution here since it does not really\nrelate to JRuyi.  You can find the solution in the source code\n\nDiscardServer.java\n.\n\n\nIf you have git-cloned the \njruyi-examples\n from Github, please go to the directory\n\n$JRUYI_EXAMPLES_HOME\n/discard.  Then build the project by running the following command.\n\n\n$ ./gradlew clean build\n\n\n\n\nIf building successfully, you should get the jar locating at \n$JRUYI_EXAMPLES_HOME\n/discard/build/libs, and you can start\nthe discard server as follows.\n\n\n$ java -jar build/libs/discard-1.0.0-SNAPSHOT.jar\n\n\n\n\n\n\nFor Maven Users:\n\n\nPlease use the following command to build the project.\n\n\n$ mvn clean package\n\n\nAnd use the following command to run the server.\n\n\n$ java -jar target/discard-1.0.0-SNAPSHOT.jar\n\n\n\n\nYou should see logs printed on console similar as follows.\n\n\n[main] INFO org.jruyi.common.internal.Scheduler - Scheduler activated: numberOfThreads=1\n[main] INFO org.jruyi.io.channel.ChannelAdmin - Activating ChannelAdmin...\n[jruyi-selector-0] INFO org.jruyi.io.channel.SelectorThread - jruyi-selector-0 started\n[main] INFO org.jruyi.io.channel.ChannelAdmin - ChannelAdmin activated\n[jruyi-selector-1] INFO org.jruyi.io.channel.SelectorThread - jruyi-selector-1 started\n[main] INFO org.jruyi.io.buffer.BufferFactory - BufferFactory: unitCapacity=8192\n[main] INFO org.jruyi.io.tcpserver.TcpAcceptor - Starting TcpAcceptor...\n[main] INFO org.jruyi.io.tcpserver.TcpAcceptor - TcpAcceptor started\n[main] INFO org.jruyi.io.tcpserver.TcpServer - Starting TcpServer[jruyi.example.discard]...\n[main] INFO org.jruyi.io.tcpserver.TcpServer - TcpServer[jruyi.example.discard] started, listening on /0:0:0:0:0:0:0:0:10009\n\n\n\n\nOK, we just got the discard server started. It's time to use telnet to make a test.\n\n\n$ telnet localhost 10009\n\n\n\n\nThen just type something and you won't get any response.\nBut you should see what you typed be dumped on the console in which the discard server started.\n\n\nCongratulations! You just learned how to use the lib \njruyi-core\n to build a discard server.  But it would be much easier\nif you use \njruyi\n runtime.  Let me show you how easy it is.\n\n\n1. Start JRuyi\n\uf0c1\n\n\nPlease go to \n$JRUYI_HOME\n and start JRuyi as follows.\n\n\n$ bin/ruyi\n\n\n\n\n2. Create a Session Service Endpoint\n\uf0c1\n\n\nOpen a new console and run the following command under \n$JRUYI_HOME\n to create a TCP server (Session Service) listening on port 10009.\n\n\n$ bin/ruyi-cli conf:create jruyi.me.endpoint.tcpserver jruyi.me.endpoint.id=jruyi.example.discard port=10009\n\n\n\n\nThe created TCP Server Endpoint is identified with \njruyi.example.discard\n.\n\n\nAs you see, a Session Service Endpoint of TcpServer is created by creating a configuration of \njruyi.me.endpoint.tcpserver\n.\n\n\n3. Configure the Routing Table\n\uf0c1\n\n\nRun the following command under \n$JRUYI_HOME\n to set a route.\n\n\n$ bin/ruyi-cli route:set jruyi.example.discard jruyi.me.endpoint.null\n\n\n\n\nThis is to tell Messaging Engine to dispatch any messages from endpoint \njruyi.example.discard\n to endpoint \njruyi.me.endpoint.null\n which is a builtin endpoint to swallow any messages dispatched to it.\n\n\nThat's it! You just built a discard server using JRuyi and you can use telnet to make tests.\n\n\nTo see the data that the discard server received, you can add the builtin MsgLog Filter to the filter chain of the TcpServer \njruyi.example.discard\n by running the following command under \n$JRUYI_HOME\n.\n\n\n$ bin/ruyi-cli conf:update '\"(jruyi.me.endpoint.id=jruyi.example.discard)\"' filters=jruyi.io.msglog.filter\n\n\n\n\nNow use telnet to test again.  You should see what you typed be dumped on the console in which JRuyi was started.\n\n\n4. Shutdown JRuyi\n\uf0c1\n\n\nTo shutdown JRuyi, simply press ctrl-c in the console in which JRuyi was started. Alternatively, you can run the following command under \n$JRUYI_HOME\n.\n\n\n$ bin/ruyi-cli shutdown\n\n\n\n\nBuilding an Echo Server\n\uf0c1\n\n\nIn \nBuilding a Discard Server\n, you should have got the idea of how to receive data from\nclient in JRuyi. But you might not be clear on how to send back some data to client. So next, let's show you the how-to\nby building an \necho\n server.\n\n\nThe key difference to implement an echo server is that the SessionListener need hold a reference to the \nINioService\n.\nAnd use it to send back whatever is received in method \nonMessageReceived\n.\n\n\npackage org.jruyi.example.echo;\n\nimport org.jruyi.core.INioService;\nimport org.jruyi.core.ITcpServerConfiguration;\nimport org.jruyi.io.IBuffer;\nimport org.jruyi.io.ISession;\nimport org.jruyi.io.SessionListener;\n\nclass EchoServerListener extends SessionListener<IBuffer, IBuffer> {\n\n    // Hold a reference to INioService\n    private final INioService<IBuffer, IBuffer, ? extends ITcpServerConfiguration> m_tcpServer;\n\n    EchoServerListener(INioService<IBuffer, IBuffer, ? extends ITcpServerConfiguration> tcpServer) {\n        m_tcpServer = tcpServer;\n    }\n\n    @Override\n    public void onMessageReceived(ISession session, IBuffer inMsg) {\n        // Send back whatever is received.\n        m_tcpServer.write(session, inMsg);\n    }\n}\n\n\n\n\nClass \nEchoServer\n is almost the same as class \nDiscardServer\n except that the instance of \nINioService\n need be used to\nconstruct an instance of \nEchoServerListener\n. Below is the code for \nEchoServer\n.\n\n\npackage org.jruyi.example.echo;\n\nimport org.jruyi.core.INioService;\nimport org.jruyi.core.ITcpServerConfiguration;\nimport org.jruyi.core.RuyiCore;\nimport org.jruyi.io.IBuffer;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\npublic class EchoServer {\n\n    private static final Logger c_logger = LoggerFactory.getLogger(EchoServer.class);\n\n    static class ShutdownHook extends Thread {\n\n        private final INioService<IBuffer, IBuffer, ? extends ITcpServerConfiguration> m_tcpServer;\n\n        ShutdownHook(INioService<IBuffer, IBuffer, ? extends ITcpServerConfiguration> tcpServer) {\n            m_tcpServer = tcpServer;\n        }\n\n        @Override\n        public void run() {\n            m_tcpServer.stop();\n        }\n    }\n\n    public static void main(String[] args) {\n        try {\n            // Build an Nio Service of type TcpServer\n            final INioService<IBuffer, IBuffer, ? extends ITcpServerConfiguration> tcpServer = RuyiCore\n                    .newTcpServerBuilder()\n                    .port(10007)\n                    .serviceId(\"jruyi.example.echo\")\n                    .build();\n\n            // Set sessionListener\n            tcpServer.sessionListener(new EchoServerListener(tcpServer));\n\n            // Start tcpServer\n            tcpServer.start();\n\n            // To shutdown gracefully\n            Runtime.getRuntime().addShutdownHook(new ShutdownHook(tcpServer));\n        } catch (Throwable t) {\n            c_logger.error(\"Failed to start echo service\", t);\n        }\n    }\n}\n\n\n\n\nYou can also use JRuyi runtime to build an echo server.\n\n\nAfter starting JRuyi, please execute the following commands under \n$JRUYI_HOME\n.\n\n\n# Create a TCP server listening on port 10007\n$ bin/ruyi-cli conf:create jruyi.me.endpoint.tcpserver jruyi.me.endpoint.id=jruyi.example.echo port=10007\n\n# Route any message from endpoint jruyi.example.echo back to itself\n$ bin/ruyi-cli route:set jruyi.example.echo jruyi.example.echo\n\n\n\n\nNow, you should be able to test echo server by running the following command.\n\n\n$ telnet localhost 10007\n\n\n\n\nThis time you will see that whatever you typed will be echoed.\n\n\nBuilding a Daytime Server\n\uf0c1",
            "title": "Getting Started"
        },
        {
            "location": "/getting-started/#getting-started",
            "text": "Some examples to let you get started quickly with JRuyi.  To get the source code of examples, please check  jruyi-examples  on Github.\nIn the later sections,  $JRUYI_EXAMPLES_HOME  will be used to refer to the root directory of your local copy of the repo jruyi-examples .  All the example projects are available in Gradle as well as Maven.   Note:  All the examples are given under a UNIX-like environment. It should be very straightforward for you to make them\nwork on Windows. Just use the counterpart BAT file for a shell script file mentioned in the examples. For example,\nuse ruyi.bat for ruyi and ruyi-cli.bat for ruyi-cli.   We also assume that you know how to download JRuyi.  If you don't, please go check  Download . And we will\nuse  $JRUYI_HOME  to refer to the directory where the downloaded jruyi package is unpacked.",
            "title": "Getting Started"
        },
        {
            "location": "/getting-started/#building-a-discard-server",
            "text": "Lets start with writing a  discard  server which simply throws away any received data.  To implement a discard server, simply create an  INioService \nof type TcpServer, and start it as the following code shows.  package org.jruyi.example.discard;\n\nimport org.jruyi.core.INioService;\nimport org.jruyi.core.ITcpServerConfiguration;\nimport org.jruyi.core.RuyiCore;\nimport org.jruyi.io.IBuffer;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\npublic class DiscardServer {\n\n    private static final Logger c_logger = LoggerFactory.getLogger(DiscardServer.class);\n\n    public static void main(String[] args) {\n        try {\n            // Build an Nio Service of type TcpServer\n            final INioService<IBuffer, Object, ? extends ITcpServerConfiguration> tcpServer = RuyiCore\n                    .newTcpServerBuilder()\n                    .port(10009)\n                    .serviceId(\"jruyi.example.discard\")\n                    .build();\n\n            // Start tcpServer\n            tcpServer.start();\n        } catch (Throwable t) {\n            c_logger.error(\"Failed to start discard server\", t);\n        }\n    }\n}  Simple? Yeah, it is.  But there's a problem of this code that it cannot serve as a good demo.  Because there's no prove\nthat we actually got the data sent from a client.  So lets write a session listener and log the received data.  package org.jruyi.example.discard;\n\nimport org.jruyi.common.StrUtil;\nimport org.jruyi.io.IBuffer;\nimport org.jruyi.io.ISession;\nimport org.jruyi.io.SessionListener;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nclass DiscardServerListener extends SessionListener<IBuffer, Object> {\n\n    private static final Logger c_logger = LoggerFactory.getLogger(DiscardServerListener.class);\n\n    @Override\n    public void onMessageReceived(ISession session, IBuffer inMsg) {\n        c_logger.info(StrUtil.join(\"Got data >>\", StrUtil.getLineSeparator(), inMsg));\n    }\n}  Method  DiscardServerListener.onMessageReceived  will be invoked when any data arrives. And it dumps the received data.  Next, lets hook this DiscardServerListener to the NioService before starting.  ...\n// Set sessionListener\ntcpServer.sessionListener(new DiscardServerListener());\n\n// Start tcpServer\ntcpServer.start();\n...  Now, you should/can see what data the server gets.  However, this code is still not good enough.  You may have already\nnoticed that there's a  tcpServer.start()  but no call of stop, which means the NioService does not stop gracefully when this\napplication terminates.  What should we do then?  I'm not going to discuss the solution here since it does not really\nrelate to JRuyi.  You can find the solution in the source code DiscardServer.java .  If you have git-cloned the  jruyi-examples  from Github, please go to the directory $JRUYI_EXAMPLES_HOME /discard.  Then build the project by running the following command.  $ ./gradlew clean build  If building successfully, you should get the jar locating at  $JRUYI_EXAMPLES_HOME /discard/build/libs, and you can start\nthe discard server as follows.  $ java -jar build/libs/discard-1.0.0-SNAPSHOT.jar   For Maven Users:  Please use the following command to build the project.  $ mvn clean package  And use the following command to run the server.  $ java -jar target/discard-1.0.0-SNAPSHOT.jar   You should see logs printed on console similar as follows.  [main] INFO org.jruyi.common.internal.Scheduler - Scheduler activated: numberOfThreads=1\n[main] INFO org.jruyi.io.channel.ChannelAdmin - Activating ChannelAdmin...\n[jruyi-selector-0] INFO org.jruyi.io.channel.SelectorThread - jruyi-selector-0 started\n[main] INFO org.jruyi.io.channel.ChannelAdmin - ChannelAdmin activated\n[jruyi-selector-1] INFO org.jruyi.io.channel.SelectorThread - jruyi-selector-1 started\n[main] INFO org.jruyi.io.buffer.BufferFactory - BufferFactory: unitCapacity=8192\n[main] INFO org.jruyi.io.tcpserver.TcpAcceptor - Starting TcpAcceptor...\n[main] INFO org.jruyi.io.tcpserver.TcpAcceptor - TcpAcceptor started\n[main] INFO org.jruyi.io.tcpserver.TcpServer - Starting TcpServer[jruyi.example.discard]...\n[main] INFO org.jruyi.io.tcpserver.TcpServer - TcpServer[jruyi.example.discard] started, listening on /0:0:0:0:0:0:0:0:10009  OK, we just got the discard server started. It's time to use telnet to make a test.  $ telnet localhost 10009  Then just type something and you won't get any response.\nBut you should see what you typed be dumped on the console in which the discard server started.  Congratulations! You just learned how to use the lib  jruyi-core  to build a discard server.  But it would be much easier\nif you use  jruyi  runtime.  Let me show you how easy it is.  1. Start JRuyi \uf0c1  Please go to  $JRUYI_HOME  and start JRuyi as follows.  $ bin/ruyi  2. Create a Session Service Endpoint \uf0c1  Open a new console and run the following command under  $JRUYI_HOME  to create a TCP server (Session Service) listening on port 10009.  $ bin/ruyi-cli conf:create jruyi.me.endpoint.tcpserver jruyi.me.endpoint.id=jruyi.example.discard port=10009  The created TCP Server Endpoint is identified with  jruyi.example.discard .  As you see, a Session Service Endpoint of TcpServer is created by creating a configuration of  jruyi.me.endpoint.tcpserver .  3. Configure the Routing Table \uf0c1  Run the following command under  $JRUYI_HOME  to set a route.  $ bin/ruyi-cli route:set jruyi.example.discard jruyi.me.endpoint.null  This is to tell Messaging Engine to dispatch any messages from endpoint  jruyi.example.discard  to endpoint  jruyi.me.endpoint.null  which is a builtin endpoint to swallow any messages dispatched to it.  That's it! You just built a discard server using JRuyi and you can use telnet to make tests.  To see the data that the discard server received, you can add the builtin MsgLog Filter to the filter chain of the TcpServer  jruyi.example.discard  by running the following command under  $JRUYI_HOME .  $ bin/ruyi-cli conf:update '\"(jruyi.me.endpoint.id=jruyi.example.discard)\"' filters=jruyi.io.msglog.filter  Now use telnet to test again.  You should see what you typed be dumped on the console in which JRuyi was started.  4. Shutdown JRuyi \uf0c1  To shutdown JRuyi, simply press ctrl-c in the console in which JRuyi was started. Alternatively, you can run the following command under  $JRUYI_HOME .  $ bin/ruyi-cli shutdown",
            "title": "Building a Discard Server"
        },
        {
            "location": "/getting-started/#building-an-echo-server",
            "text": "In  Building a Discard Server , you should have got the idea of how to receive data from\nclient in JRuyi. But you might not be clear on how to send back some data to client. So next, let's show you the how-to\nby building an  echo  server.  The key difference to implement an echo server is that the SessionListener need hold a reference to the  INioService .\nAnd use it to send back whatever is received in method  onMessageReceived .  package org.jruyi.example.echo;\n\nimport org.jruyi.core.INioService;\nimport org.jruyi.core.ITcpServerConfiguration;\nimport org.jruyi.io.IBuffer;\nimport org.jruyi.io.ISession;\nimport org.jruyi.io.SessionListener;\n\nclass EchoServerListener extends SessionListener<IBuffer, IBuffer> {\n\n    // Hold a reference to INioService\n    private final INioService<IBuffer, IBuffer, ? extends ITcpServerConfiguration> m_tcpServer;\n\n    EchoServerListener(INioService<IBuffer, IBuffer, ? extends ITcpServerConfiguration> tcpServer) {\n        m_tcpServer = tcpServer;\n    }\n\n    @Override\n    public void onMessageReceived(ISession session, IBuffer inMsg) {\n        // Send back whatever is received.\n        m_tcpServer.write(session, inMsg);\n    }\n}  Class  EchoServer  is almost the same as class  DiscardServer  except that the instance of  INioService  need be used to\nconstruct an instance of  EchoServerListener . Below is the code for  EchoServer .  package org.jruyi.example.echo;\n\nimport org.jruyi.core.INioService;\nimport org.jruyi.core.ITcpServerConfiguration;\nimport org.jruyi.core.RuyiCore;\nimport org.jruyi.io.IBuffer;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\npublic class EchoServer {\n\n    private static final Logger c_logger = LoggerFactory.getLogger(EchoServer.class);\n\n    static class ShutdownHook extends Thread {\n\n        private final INioService<IBuffer, IBuffer, ? extends ITcpServerConfiguration> m_tcpServer;\n\n        ShutdownHook(INioService<IBuffer, IBuffer, ? extends ITcpServerConfiguration> tcpServer) {\n            m_tcpServer = tcpServer;\n        }\n\n        @Override\n        public void run() {\n            m_tcpServer.stop();\n        }\n    }\n\n    public static void main(String[] args) {\n        try {\n            // Build an Nio Service of type TcpServer\n            final INioService<IBuffer, IBuffer, ? extends ITcpServerConfiguration> tcpServer = RuyiCore\n                    .newTcpServerBuilder()\n                    .port(10007)\n                    .serviceId(\"jruyi.example.echo\")\n                    .build();\n\n            // Set sessionListener\n            tcpServer.sessionListener(new EchoServerListener(tcpServer));\n\n            // Start tcpServer\n            tcpServer.start();\n\n            // To shutdown gracefully\n            Runtime.getRuntime().addShutdownHook(new ShutdownHook(tcpServer));\n        } catch (Throwable t) {\n            c_logger.error(\"Failed to start echo service\", t);\n        }\n    }\n}  You can also use JRuyi runtime to build an echo server.  After starting JRuyi, please execute the following commands under  $JRUYI_HOME .  # Create a TCP server listening on port 10007\n$ bin/ruyi-cli conf:create jruyi.me.endpoint.tcpserver jruyi.me.endpoint.id=jruyi.example.echo port=10007\n\n# Route any message from endpoint jruyi.example.echo back to itself\n$ bin/ruyi-cli route:set jruyi.example.echo jruyi.example.echo  Now, you should be able to test echo server by running the following command.  $ telnet localhost 10007  This time you will see that whatever you typed will be echoed.",
            "title": "Building an Echo Server"
        },
        {
            "location": "/getting-started/#building-a-daytime-server",
            "text": "",
            "title": "Building a Daytime Server"
        },
        {
            "location": "/user-guide/",
            "text": "Overview\n\uf0c1\n\n\nJRuyi is built on OSGi platform which mainly uses \nOSGi Declarative Services\n\nas the service component model itself, and uses \nOSGi Configuration Admin Service\n\nfor configuring components.\n\n\nArchitecture\n\uf0c1\n\n\n\n\nJRuyi runtime consists of JRuyi Core and JRuyi Messaging.\n\n\nJRuyi Core consists of the following components: \nChannel Admin\n, \nFilter Chain\n, \nSession Services\n, \nSession Listener\n,\n\nScheduler\n and \nTimer Admin\n.  It provides an event-driven IO channel framework implemented in the\n\nReactor pattern\n to read/write data from/to the network.\nBuilt on this IO channel framework, there are 8 types of Session Services.  They are \nTcpServer\n, \nUdpServer\n,\n\nShortConn\n, \nTcpClient\n, \nTcpClientMux\n, \nConnPool\n, \nConnPoolMux\n and \nUdpClient\n.\n\n\nJRuyi Messaging consists of the following components: \nEndpoints\n, \nPrehandlers\n, \nPosthandlers\n, \nMessaging Engine\n and \nThread Pool Executor\n.",
            "title": "User Guide"
        },
        {
            "location": "/user-guide/#overview",
            "text": "JRuyi is built on OSGi platform which mainly uses  OSGi Declarative Services \nas the service component model itself, and uses  OSGi Configuration Admin Service \nfor configuring components.",
            "title": "Overview"
        },
        {
            "location": "/user-guide/#architecture",
            "text": "JRuyi runtime consists of JRuyi Core and JRuyi Messaging.  JRuyi Core consists of the following components:  Channel Admin ,  Filter Chain ,  Session Services ,  Session Listener , Scheduler  and  Timer Admin .  It provides an event-driven IO channel framework implemented in the Reactor pattern  to read/write data from/to the network.\nBuilt on this IO channel framework, there are 8 types of Session Services.  They are  TcpServer ,  UdpServer , ShortConn ,  TcpClient ,  TcpClientMux ,  ConnPool ,  ConnPoolMux  and  UdpClient .  JRuyi Messaging consists of the following components:  Endpoints ,  Prehandlers ,  Posthandlers ,  Messaging Engine  and  Thread Pool Executor .",
            "title": "Architecture"
        }
    ]
}